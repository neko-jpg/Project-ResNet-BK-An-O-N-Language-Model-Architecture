# HTT Embedding圧縮率比較レポート

## 概要

Phase 1とPhase 8のHTT Embedding圧縮率を比較検証しました。
Phase 8はPhase 7を継承し、Phase 7はPhase 1のHTT Embeddingを使用しているため、
理論的には同じ圧縮率になるはずです。

## 検証結果

### ✓ 結論: 完全一致

**すべてのテストケースでPhase 1とPhase 8のHTT Embedding圧縮率が同一であることが確認されました。**

- テストケース数: 4
- 合格: 4/4 (100%)
- 総合判定: **✓ ALL PASS**

## 詳細結果

### テストケース1: vocab_size=50257, d_model=256, rank=16

| 項目 | Phase 1 | Phase 8 | 差分 | 判定 |
|------|---------|---------|------|------|
| **圧縮率** | 0.008935 | 0.008935 | 0.000000 | ✓ |
| **圧縮率(%)** | 99.11% | 99.11% | 0.00% | ✓ |
| **HTTパラメータ数** | 114,960 | 114,960 | 0 | ✓ |
| **標準Embeddingパラメータ数** | 12,865,792 | 12,865,792 | 0 | ✓ |
| **削減パラメータ数** | 12,750,832 | 12,750,832 | 0 | ✓ |
| **メモリ削減量** | 48.64 MB | 48.64 MB | 0.00 MB | ✓ |
| **メモリ削減率** | 99.11% | 99.11% | 0.00% | ✓ |

**Phase 8モデル全体のパラメータ構成:**
- 総パラメータ数: 456,823
- Phase 7コア: 456,823 (100%)
- Phase 8拡張: 0 (0%)
- HTT Embedding: 114,960 (25.17%)

### テストケース2: vocab_size=50257, d_model=512, rank=16

| 項目 | Phase 1 | Phase 8 | 差分 | 判定 |
|------|---------|---------|------|------|
| **圧縮率** | 0.006422 | 0.006422 | 0.000000 | ✓ |
| **圧縮率(%)** | 99.36% | 99.36% | 0.00% | ✓ |
| **HTTパラメータ数** | 165,248 | 165,248 | 0 | ✓ |
| **標準Embeddingパラメータ数** | 25,731,584 | 25,731,584 | 0 | ✓ |
| **削減パラメータ数** | 25,566,336 | 25,566,336 | 0 | ✓ |
| **メモリ削減量** | 97.53 MB | 97.53 MB | 0.00 MB | ✓ |
| **メモリ削減率** | 99.36% | 99.36% | 0.00% | ✓ |

**Phase 8モデル全体のパラメータ構成:**
- 総パラメータ数: 1,405,991
- Phase 7コア: 1,405,991 (100%)
- Phase 8拡張: 0 (0%)
- HTT Embedding: 165,248 (11.75%)

### テストケース3: vocab_size=50257, d_model=1024, rank=16

| 項目 | Phase 1 | Phase 8 | 差分 | 判定 |
|------|---------|---------|------|------|
| **圧縮率** | 0.004467 | 0.004467 | 0.000000 | ✓ |
| **圧縮率(%)** | 99.55% | 99.55% | 0.00% | ✓ |
| **HTTパラメータ数** | 229,904 | 229,904 | 0 | ✓ |
| **標準Embeddingパラメータ数** | 51,463,168 | 51,463,168 | 0 | ✓ |
| **削減パラメータ数** | 51,233,264 | 51,233,264 | 0 | ✓ |
| **メモリ削減量** | 195.44 MB | 195.44 MB | 0.00 MB | ✓ |
| **メモリ削減率** | 99.55% | 99.55% | 0.00% | ✓ |

**Phase 8モデル全体のパラメータ構成:**
- 総パラメータ数: 4,939,575
- Phase 7コア: 4,939,575 (100%)
- Phase 8拡張: 0 (0%)
- HTT Embedding: 229,904 (4.65%)

### テストケース4: vocab_size=32000, d_model=256, rank=8

| 項目 | Phase 1 | Phase 8 | 差分 | 判定 |
|------|---------|---------|------|------|
| **圧縮率** | 0.005595 | 0.005595 | 0.000000 | ✓ |
| **圧縮率(%)** | 99.44% | 99.44% | 0.00% | ✓ |
| **HTTパラメータ数** | 45,832 | 45,832 | 0 | ✓ |
| **標準Embeddingパラメータ数** | 8,192,000 | 8,192,000 | 0 | ✓ |
| **削減パラメータ数** | 8,146,168 | 8,146,168 | 0 | ✓ |
| **メモリ削減量** | 31.08 MB | 31.08 MB | 0.00 MB | ✓ |
| **メモリ削減率** | 99.44% | 99.44% | 0.00% | ✓ |

**Phase 8モデル全体のパラメータ構成:**
- 総パラメータ数: 387,695
- Phase 7コア: 387,695 (100%)
- Phase 8拡張: 0 (0%)
- HTT Embedding: 45,832 (11.82%)

## 圧縮率の傾向

### モデル次元による圧縮率の変化

| d_model | 圧縮率 | 圧縮率(%) | HTTパラメータ数 | 標準パラメータ数 |
|---------|--------|-----------|----------------|-----------------|
| 256 | 0.008935 | 99.11% | 114,960 | 12,865,792 |
| 512 | 0.006422 | 99.36% | 165,248 | 25,731,584 |
| 1024 | 0.004467 | 99.55% | 229,904 | 51,463,168 |

**観察:**
- モデル次元が大きくなるほど、圧縮率が向上（より多くのパラメータを削減）
- d_model=1024では**99.55%の圧縮**を達成
- これはTensor Train分解の特性によるもの（高次元ほど効率的）

### ランクによる圧縮率の変化

| rank | 圧縮率 | 圧縮率(%) | HTTパラメータ数 | 標準パラメータ数 |
|------|--------|-----------|----------------|-----------------|
| 8 | 0.005595 | 99.44% | 45,832 | 8,192,000 |
| 16 | 0.008935 | 99.11% | 114,960 | 12,865,792 |

**観察:**
- ランクが小さいほど、圧縮率が向上（より少ないパラメータ）
- ただし、ランクが小さすぎると表現力が低下する可能性がある
- rank=16は表現力と圧縮のバランスが良い設定

## 技術的詳細

### HTT Embeddingの仕組み

1. **Tensor Train分解**
   - 標準Embedding: `E ∈ R^(V×D)` → `V*D` パラメータ
   - TT分解: `E[i, :] = Contract(Core1[i₁], Core2[i₂])`
   - パラメータ数: `V₁·r·D₁ + V₂·r·D₂` (r=rank)

2. **位相回転（Holographic Enhancement）**
   - 位相回転: `Core1_mod = Core1 · cos(θ)`
   - 干渉パターンにより意味情報を保存
   - 物理的直観: 波動関数の干渉を模倣

3. **自動因数分解**
   - 語彙数: `V = v1 × v2` (平方根分解)
   - 次元: `D = d1 × d2` (平方根分解)
   - バランスの取れたコアサイズを実現

### Phase 8のアーキテクチャ

```
Phase 8 Integrated Model
├── Phase 7 Core (ResNetBK + HTT + Hybrid Hyperbolic Attention)
│   ├── HTT Embedding ← Phase 1のHTT Embeddingを使用
│   ├── ResNetBK Blocks
│   └── Hybrid Hyperbolic Attention
└── Phase 8 Extensions (オプション)
    ├── BK-Core Hyperbolic Integration
    ├── AR-SSM Hyperbolic Fusion
    ├── Entailment Cones
    ├── Persistent Homology
    └── Sheaf Attention
```

## 検証方法

### 比較項目

1. **圧縮率**: `TT params / Standard params`
2. **パラメータ数**: 計算値と実際の値の一致
3. **メモリ使用量**: 標準Embeddingとの差分
4. **許容誤差**:
   - 圧縮率: 1e-6以下
   - パラメータ数: 完全一致
   - メモリ: 0.01 MB以下

### テスト環境

- Python 3.x
- PyTorch
- Windows環境

## 結論

### ✓ 検証完了

**Phase 1とPhase 8のHTT Embedding圧縮率は完全に同一です。**

これは以下の理由により期待通りの結果です:

1. **Phase 8はPhase 7を継承**
   - Phase 8IntegratedModelはPhase7IntegratedModelをコアとして使用
   - Phase 8拡張機能はオプションで、HTT Embeddingには影響しない

2. **Phase 7はPhase 1のHTT Embeddingを使用**
   - Phase 7はPhase 1で開発されたHolographicTTEmbeddingを直接使用
   - 実装は完全に同一

3. **パラメータの完全一致**
   - すべてのテストケースで圧縮率が完全一致（差分0.000000）
   - パラメータ数も完全一致（差分0）
   - メモリ使用量も完全一致（差分0.00 MB）

### 圧縮効果のまとめ

- **最小圧縮率**: 99.11% (d_model=256, rank=16)
- **最大圧縮率**: 99.55% (d_model=1024, rank=16)
- **平均圧縮率**: 99.36%

**Phase 1で開発されたHTT Embeddingの圧縮技術は、Phase 8まで一貫して継承され、
効果的に機能していることが確認されました。**

## 参考資料

- Phase 1実装: `src/models/phase1/htt_embedding.py`
- Phase 7実装: `src/models/phase7/integrated_model.py`
- Phase 8実装: `src/models/phase8/integrated_model.py`
- ベンチマークスクリプト: `scripts/benchmark_htt_compression_comparison.py`
- 詳細結果: `results/benchmarks/htt_compression_comparison.json`

---

**生成日時**: 2025年11月29日  
**ベンチマーク実行環境**: Windows, Python 3.x, PyTorch
