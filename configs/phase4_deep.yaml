# Phase 4 Deep Architecture (User Request)
# "Deep and Thin" Configuration

# Architecture
model_type: resnet_bk
d_model: 1024
n_layers: 12
n_seq: 768  # Kept at 768 to ensure memory safety on 10GB/8GB, but can be scaled if successful
num_experts: 4
top_k: 1
use_bitnet: true
use_symplectic: true
symplectic_dt: 0.1
use_non_hermitian: true
use_birman_schwinger: true
epsilon: 1.0
use_mourre: true
use_lap: true

# Training
batch_size: 2  # Conservative for 12 layers
epochs: 5      # Increased from 3 as per plan
learning_rate: 0.001
grad_clip: 0.5
use_mixed_precision: true
use_gradient_checkpointing: true
use_custom_kernels: true

# Data
dataset: configs/dataset_mixing.yaml
data_limit: 100000000  # 100M tokens limit
