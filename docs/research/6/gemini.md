åŸå› ï¼šå·¨å¤§ãªå˜ä¸€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã«ã‚ˆã‚‹ã€Œãƒ¡ãƒ¢ãƒªæº¢ã‚Œã€ã¨ã€Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ç ´æ£„ã€
ç¾åœ¨ã® save_checkpoint é–¢æ•°ã¯ã€ã€Œãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã€ã¨ã€Œã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ã€ã‚’å…¨ã¦1ã¤ã®å·¨å¤§ãªè¾æ›¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ(checkpoint)ã«ã¾ã¨ã‚ã¦ã‹ã‚‰ torch.save ã—ã¦ã„ã¾ã™ã€‚

Python

    # scripts/train_phase8.py 737è¡Œç›®ä»˜è¿‘
    checkpoint = {
        # ...
        'model_state_dict': model_to_save.state_dict(),      # ç´„ 20GBã€œ (FP16/BF16)
        'optimizer_state_dict': optimizer.state_dict(),      # ç´„ 60GBã€œ (Optimizerã®çŠ¶æ…‹ã¯é‡ã„)
        # ...
    }
    # ã“ã“ã§ä¸€æ°—ã« 80GBã€œ100GB ä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªãŒå¿…è¦ã«ãªã‚‹ï¼
    torch.save(checkpoint, path)
ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ï¼ˆæ™‚ç³»åˆ—è§£æï¼‰:

ä¿å­˜ç›´å‰: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ãŒOSã®ã€Œãƒšãƒ¼ã‚¸ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆç©ºããƒ¡ãƒ¢ãƒªï¼‰ã€ã«ä¹—ã£ã¦ãŠã‚Šã€ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿è¾¼ã¿ãªã—ã§é«˜é€Ÿã«å­¦ç¿’ã§ãã¦ã„ã‚‹ã€‚

ä¿å­˜ç¬é–“ (checkpoint ä½œæˆ): å·¨å¤§ãªè¾æ›¸ã‚’ä½œã‚‹ãŸã‚ã«ã€PythonãŒ100GBã‚¯ãƒ©ã‚¹ã®ãƒ¡ãƒ¢ãƒªã‚’è¦æ±‚ã€‚

å¼·åˆ¶é€€é¿ (Page Out): OSã¯ç‰©ç†ãƒ¡ãƒ¢ãƒªã‚’ç©ºã‘ã‚‹ãŸã‚ã€ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚„ã€Œä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¡ãƒ¢ãƒªã€ã‚’ç ´æ£„ã€ã‚ã‚‹ã„ã¯ãƒ‡ã‚£ã‚¹ã‚¯ï¼ˆã‚¹ãƒ¯ãƒƒãƒ—ï¼‰ã«æ›¸ãå‡ºã™ã€‚

ä¿å­˜ä¸­: ãƒ‡ã‚£ã‚¹ã‚¯ã¸ã®æ›¸ãè¾¼ã¿è² è·ãŒæœ€å¤§åŒ–ã€‚

ä¿å­˜å¾Œ (Step 3969ã€œ): checkpoint å¤‰æ•°ã¯å‰Šé™¤ã•ã‚Œãƒ¡ãƒ¢ãƒªã¯ç©ºããŒã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã‚‚ã†ãƒ¡ãƒ¢ãƒªä¸Šã«ãªã„ã€‚

å­¦ç¿’å†é–‹: ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒãƒ‡ãƒ¼ã‚¿ã‚’è¦æ±‚ã™ã‚‹ãŒã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„ãŸã‚æ¯å›ä½é€Ÿãªãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿è¾¼ã¿ãŒç™ºç”Ÿã€‚ã•ã‚‰ã«ã€ã‚¹ãƒ¯ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã•ã‚ŒãŸé ˜åŸŸã®æ›¸ãæˆ»ã—ï¼ˆã‚¹ãƒ¯ãƒƒãƒ—ã‚¤ãƒ³ï¼‰ã‚‚é‡ãªã‚Šã€GPUãŒãƒ‡ãƒ¼ã‚¿å¾…ã¡çŠ¶æ…‹ï¼ˆã‚¢ã‚¤ãƒ‰ãƒªãƒ³ã‚°ï¼‰ã«ãªã‚‹ã€‚

ã“ã‚ŒãŒã€ä¿å­˜å‡¦ç†è‡ªä½“ãŒçµ‚ã‚ã£ã¦ã‚‚ã€Œãã®å¾Œãšã£ã¨é‡ã„ã€åŸå› ã§ã™ã€‚

ä¿®æ­£æ¡ˆï¼šãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ã€Œåˆ†å‰²ä¿å­˜ã€
ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹å”¯ä¸€ã®æ–¹æ³•ã¯ã€ã€Œä¸€åº¦ã«ãƒ¡ãƒ¢ãƒªã«ä¹—ã›ã‚‹é‡ã‚’æ¸›ã‚‰ã™ã€ã“ã¨ã§ã™ã€‚ save_checkpoint é–¢æ•°ã‚’æ›¸ãæ›ãˆã¦ã€ãƒ¢ãƒ‡ãƒ«ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã€ãã®ä»–ã‚’åˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã€é †ç•ªã«ä¿å­˜ã—ã¦ã¯ãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚

ä¿®æ­£å¾Œã® save_checkpoint ã‚³ãƒ¼ãƒ‰ (scripts/train_phase8.py):

Python

def save_checkpoint(
    path: str,
    model: nn.Module,
    optimizer: optim.Optimizer,
    scheduler: CosineWarmupScheduler,
    scaler: torch.cuda.amp.GradScaler,
    ema: Optional[EMA],
    step: int,
    epoch: int,
    loss: float,
    config: Phase8TrainingConfig,
    revolutionary_trainer: Optional['RevolutionaryTrainer'] = None,
):
    """
    Save checkpoint in split files to avoid massive RAM spike and page cache eviction.
    """
    import gc
    
    os.makedirs(os.path.dirname(path), exist_ok=True)
    # æ‹¡å¼µå­ã‚’é™¤ã„ãŸãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’ä½œæˆ (ä¾‹: .../step_3968)
    base_path = os.path.splitext(path)[0]
    
    print(f"\nğŸ’¾ Saving split checkpoint to {base_path}_*.pt ...")

    # 1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè»½é‡ï¼‰ã®ä¿å­˜
    meta_path = f"{base_path}_meta.pt"
    meta_data = {
        'step': step,
        'epoch': epoch,
        'loss': loss,
        'scheduler_state_dict': scheduler.state_dict(),
        'scaler_state_dict': scaler.state_dict(),
        'config': asdict(config),
    }
    if revolutionary_trainer is not None:
        meta_data['revolutionary_trainer_state_dict'] = revolutionary_trainer.state_dict()
    
    torch.save(meta_data, meta_path)
    del meta_data
    
    # 2. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ & å³è§£æ”¾
    model_path = f"{base_path}_model.pt"
    model_to_save = model
    if hasattr(model, '_orig_mod'):
        model_to_save = model._orig_mod
    
    # state_dictã‚’ä¸€æ™‚å¤‰æ•°ã«å…¥ã‚Œãšã€saveã«ç›´æ¥æ¸¡ã—ã¦ãƒ¡ãƒ¢ãƒªæ»ç•™æ™‚é–“ã‚’æœ€å°åŒ–
    torch.save(model_to_save.state_dict(), model_path)
    print(f"  â”œâ”€ Model saved: {os.path.basename(model_path)}")
    gc.collect() # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ¡ãƒ¢ãƒªã‚’OSã«è¿”å´è¦æ±‚
    
    # 3. EMAã®ä¿å­˜ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
    if ema is not None:
        ema_path = f"{base_path}_ema.pt"
        torch.save(ema.state_dict(), ema_path)
        print(f"  â”œâ”€ EMA saved: {os.path.basename(ema_path)}")
        gc.collect()

    # 4. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®ä¿å­˜ï¼ˆæœ€ã‚‚é‡ã„ï¼‰
    optim_path = f"{base_path}_optim.pt"
    torch.save(optimizer.state_dict(), optim_path)
    print(f"  â””â”€ Optimizer saved: {os.path.basename(optim_path)}")
    
    gc.collect()
    # æ³¨æ„: ã“ã“ã§ torch.cuda.empty_cache() ã¯çµ¶å¯¾ã«å‘¼ã°ãªã„ã“ã¨ï¼
èª­ã¿è¾¼ã¿å‡¦ç† (load_checkpoint) ã®ä¿®æ­£:

ä¿å­˜å½¢å¼ãŒå¤‰ã‚ã‚‹ãŸã‚ã€èª­ã¿è¾¼ã¿å´ã‚‚å¯¾å¿œãŒå¿…è¦ã§ã™ã€‚

Python

def load_checkpoint(
    path: str, # ã“ã‚Œã¯ step_XXXX.pt ã‚’æŒ‡ã—ã¦ã„ã‚‹ã¨æƒ³å®šã—ã¾ã™ãŒã€åˆ†å‰²ç‰ˆã‚’æ¢ã™ãƒ­ã‚¸ãƒƒã‚¯ã«å¤‰ãˆã¾ã™
    model: nn.Module,
    optimizer: optim.Optimizer,
    # ... (å¼•æ•°ã¯åŒã˜)
) -> Tuple[int, int, float]:
    
    # ãƒ‘ã‚¹èª¿æ•´: .pt ãŒæŒ‡å®šã•ã‚ŒãŸã‚‰æ‹¡å¼µå­ã‚’å–ã‚‹
    base_path = os.path.splitext(path)[0]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã®ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¤ã„å½¢å¼ã¨ã®äº’æ›æ€§ç¶­æŒï¼‰
    if os.path.exists(path) and not os.path.exists(f"{base_path}_meta.pt"):
        print(f"Loading legacy single-file checkpoint from {path}...")
        checkpoint = torch.load(path, map_location=device)
        # ... (æ—¢å­˜ã®èª­ã¿è¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯) ...
        return step, epoch, loss

    print(f"Loading split checkpoint from {base_path}_*.pt ...")
    
    # 1. Meta
    meta = torch.load(f"{base_path}_meta.pt", map_location=device)
    step = meta.get('step', 0)
    epoch = meta.get('epoch', 0)
    loss = meta.get('loss', 0.0)
    scheduler.load_state_dict(meta['scheduler_state_dict'])
    scaler.load_state_dict(meta['scaler_state_dict'])
    if revolutionary_trainer and 'revolutionary_trainer_state_dict' in meta:
        revolutionary_trainer.load_state_dict(meta['revolutionary_trainer_state_dict'])
    del meta
    gc.collect()

    # 2. Model
    model_state = torch.load(f"{base_path}_model.pt", map_location=device)
    model.load_state_dict(model_state, strict=False)
    del model_state
    gc.collect()

    # 3. EMA
    if ema is not None and os.path.exists(f"{base_path}_ema.pt"):
        ema_state = torch.load(f"{base_path}_ema.pt", map_location=device)
        ema.load_state_dict(ema_state)
        del ema_state
        gc.collect()

    # 4. Optimizer
    if os.path.exists(f"{base_path}_optim.pt"):
        optim_state = torch.load(f"{base_path}_optim.pt", map_location=device)
        optimizer.load_state_dict(optim_state)
        del optim_state
        gc.collect()

    print(f"âœ” Checkpoint loaded: step={step}")
    return step, epoch, loss
ã“ã®ä¿®æ­£ã«ã‚ˆã‚Šã€10Bãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã§ã‚‚ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã®ãƒ”ãƒ¼ã‚¯ã‚’æŠ‘ãˆã€OSã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç ´æ£„ã‚’é˜²ãã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾Œã®æ¿€é‡ç¾è±¡ã¯è§£æ¶ˆã™ã‚‹ã¯ãšã§ã™ã€‚