{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-BK Interpretability\n",
    "\n",
    "Visualize and understand ResNet-BK internals.\n",
    "\n",
    "This notebook visualizes:\n",
    "- G_ii diagonal elements (real and imaginary)\n",
    "- Learned potential v_i\n",
    "- Expert routing patterns\n",
    "- Attention-like patterns from BK-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets torch matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('src'):\n",
    "    !git clone https://github.com/YOUR_USERNAME/resnet-bk.git\n",
    "    %cd resnet-bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from src.models import LanguageModel\n",
    "from src.utils import get_data_loader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoints/resnet_bk_final.pt', map_location=device)\n",
    "config = checkpoint['config']\n",
    "\n",
    "model = LanguageModel(**config).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize G_ii Diagonal Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample input\n",
    "train_data, vocab, get_batch = get_data_loader(20, 128)\n",
    "x_batch, _ = get_batch(train_data, 0)\n",
    "x_batch = x_batch.t().contiguous().to(device)\n",
    "\n",
    "# Forward pass and extract G_ii\n",
    "with torch.no_grad():\n",
    "    # Hook to capture BK-Core output\n",
    "    G_ii_features = []\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        G_ii_features.append(output.cpu())\n",
    "    \n",
    "    hook = model.blocks[0].bk_layer.output_proj.register_forward_hook(hook_fn)\n",
    "    _ = model(x_batch)\n",
    "    hook.remove()\n",
    "\n",
    "# Visualize first sample\n",
    "features = G_ii_features[0][0].numpy()  # (N, 2)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(features[:, 0], label='Real(G_ii)')\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.set_title('Real Part of G_ii')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(features[:, 1], label='Imag(G_ii)', color='orange')\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.set_title('Imaginary Part of G_ii')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Potential v_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract potential values\n",
    "with torch.no_grad():\n",
    "    v_values = []\n",
    "    \n",
    "    def hook_v(module, input, output):\n",
    "        v_values.append(output.cpu())\n",
    "    \n",
    "    hook = model.blocks[0].bk_layer.v_proj.register_forward_hook(hook_v)\n",
    "    _ = model(x_batch)\n",
    "    hook.remove()\n",
    "\n",
    "v = v_values[0][0].squeeze().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(v)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Potential v_i')\n",
    "plt.title('Learned Potential Across Sequence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Potential statistics:\")\n",
    "print(f\"  Mean: {v.mean():.4f}\")\n",
    "print(f\"  Std: {v.std():.4f}\")\n",
    "print(f\"  Min: {v.min():.4f}\")\n",
    "print(f\"  Max: {v.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Extract and visualize BK-Core features\n",
    "- Analyze learned potential patterns\n",
    "- Understand model internals\n",
    "\n",
    "**Next steps:**\n",
    "- Analyze expert routing patterns\n",
    "- Compare patterns across different layers\n",
    "- Correlate patterns with linguistic structure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
