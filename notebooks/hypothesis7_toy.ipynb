{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis-7 Hybrid Gradient Toy Model\n",
    "\n",
    "1次元ポテンシャル $G(v)=\\frac{1}{v + i\\varepsilon}$ に対し、\n",
    "通常勾配とHypothesis-7型ハイブリッド勾配の収束速度を比較する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimizer(alpha: float, steps: int = 400, lr: float = 0.05):\n",
    "    # vを学習し、目標G*に合わせる\n",
    "    v = torch.tensor(2.0, device=device)\n",
    "    eps = torch.tensor(0.1, device=device)\n",
    "    target = torch.tensor(0.5 + 0.0j, device=device)\n",
    "    losses = []\n",
    "    for _ in range(steps):\n",
    "        G = 1.0 / (v + 1j * eps)\n",
    "        loss = torch.abs(G - target) ** 2\n",
    "        losses.append(float(loss))\n",
    "        # 理論勾配: dG/dv = -1/(v + i eps)^2\n",
    "        grad_theory = -1.0 / (v + 1j * eps) ** 2\n",
    "        grad_loss = 2 * (G - target) * grad_theory\n",
    "        # Hypothesis-7勾配: 逆二乗を安定化して混合\n",
    "        denom = (v + 1j * eps) ** 2\n",
    "        denom_mag = torch.abs(denom)\n",
    "        denom = torch.where(denom_mag < 1e-3, denom / (denom_mag + 1e-9) * 1e-3, denom)\n",
    "        grad_h7 = 2 * (G - target) * (1.0 / (denom + 1e-6))\n",
    "        grad = (1 - alpha) * grad_loss + alpha * grad_h7\n",
    "        v = v - lr * grad.real  # 実数パラメータのみ更新\n",
    "    return losses\n",
    "\n",
    "loss_plain = run_optimizer(alpha=0.0)\n",
    "loss_hybrid = run_optimizer(alpha=0.5)\n",
    "iters = list(range(len(loss_plain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogy(iters, loss_plain, label=\"GD (alpha=0.0)\")\n",
    "plt.semilogy(iters, loss_hybrid, label=\"Hybrid (alpha=0.5)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Hypothesis-7 Hybrid vs Plain Gradient\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_below(losses, threshold=1e-3):\n",
    "    for i, l in enumerate(losses):\n",
    "        if l < threshold:\n",
    "            return i\n",
    "    return len(losses)\n",
    "\n",
    "plain_iter = first_below(loss_plain)\n",
    "hybrid_iter = first_below(loss_hybrid)\n",
    "print(f\"Iterations to loss<1e-3 -> plain: {plain_iter}, hybrid: {hybrid_iter}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
