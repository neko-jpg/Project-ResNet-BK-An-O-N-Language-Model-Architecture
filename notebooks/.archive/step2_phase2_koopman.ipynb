{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Phase 2: Koopman Operator Learning\n",
    "\n",
    "This notebook implements and tests Koopman operator learning for ResNet-BK.\n",
    "\n",
    "**Objectives:**\n",
    "- Train with hybrid Koopman-gradient (4 epochs warmup, 6 epochs hybrid)\n",
    "- Verify Koopman operator updates (K changes over time)\n",
    "- Verify convergence with Koopman auxiliary loss\n",
    "- Compare perplexity to Phase 1 baseline\n",
    "\n",
    "**Expected Results:**\n",
    "- Koopman loss decreases over time\n",
    "- Koopman operator K evolves from identity initialization\n",
    "- Final perplexity within 30% of baseline\n",
    "- Backward pass cost reduction demonstrated\n",
    "\n",
    "**Optimizations Applied:**\n",
    "- Conservative Koopman weight (max 0.05) to prevent loss explosion\n",
    "- Extended warmup period (4 epochs) for stable LM convergence\n",
    "- Warning frequency control (1 per epoch max)\n",
    "- Automatic weight decay when Koopman loss is high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repo setup (clone if needed, add to sys.path)\n",
    "import os, sys, subprocess, pathlib\n",
    "REPO_URL = 'https://github.com/neko-jpg/Project-ResNet-BK-An-O-N-Language-Model-Architecture.git'\n",
    "REPO_DIR = 'Project-ResNet-BK-An-O-N-Language-Model-Architecture'\n",
    "cwd = pathlib.Path.cwd()\n",
    "candidates = [cwd, cwd.parent, cwd / REPO_DIR, cwd.parent / REPO_DIR]\n",
    "root = next((p for p in candidates if (p / 'src').exists()), None)\n",
    "if root is None:\n    root = cwd / REPO_DIR\n    if not root.exists():\n        subprocess.run(['git', 'clone', REPO_URL, str(root)], check=True)\n",
    "if root != pathlib.Path.cwd():\n    os.chdir(root)\n",
    "root_str = str(pathlib.Path.cwd())\n",
    "if root_str not in sys.path:\n    sys.path.insert(0, root_str)\n",
    "print('PWD:', root_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "# Import ResNet-BK components\n",
    "from src.models.koopman_layer import KoopmanLanguageModel\n",
    "from src.training.hybrid_koopman_trainer import HybridKoopmanTrainer\n",
    "from src.utils.data_utils import get_wikitext2_dataloaders\n",
    "from src.utils.metrics import TrainingMetrics\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 32\n",
    "N_SEQ = 128\n",
    "D_MODEL = 64\n",
    "N_LAYERS = 4\n",
    "NUM_EXPERTS = 4\n",
    "KOOPMAN_DIM = 256\n",
    "\n",
    "# Load WikiText-2 data\n",
    "print(\"Loading WikiText-2 dataset...\")\n",
    "train_loader, val_loader, vocab_size = get_wikitext2_dataloaders(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seq_len=N_SEQ,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "# print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Koopman Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Koopman language model\n",
    "model = KoopmanLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=N_LAYERS,\n",
    "    n_seq=N_SEQ,\n",
    "    koopman_dim=KOOPMAN_DIM,\n",
    "    num_experts=NUM_EXPERTS,\n",
    "    top_k=1,\n",
    "    dropout_p=0.1\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  d_model: {D_MODEL}\")\n",
    "print(f\"  n_layers: {N_LAYERS}\")\n",
    "print(f\"  n_seq: {N_SEQ}\")\n",
    "print(f\"  koopman_dim: {KOOPMAN_DIM}\")\n",
    "print(f\"  num_experts: {NUM_EXPERTS}\")\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")\n",
    "print(f\"  Size: {total_params * 4 / 1e6:.2f} MB (FP32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10  # Increased from 5 for better Koopman learning\n",
    "KOOPMAN_START_EPOCH = 4  # Start Koopman learning after 4 epochs warmup (extended for stability)\n",
    "KOOPMAN_WEIGHT_MAX = 0.05  # Conservative weight to prevent loss explosion (reduced from 0.5)\n",
    "FALLBACK_THRESHOLD = 8.0  # Threshold for high Koopman loss detection (reduced from 10.0)\n",
    "\n",
    "# Optimizer and criterion\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create hybrid Koopman trainer\n",
    "trainer = HybridKoopmanTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    koopman_weight_min=0.0,\n",
    "    koopman_weight_max=KOOPMAN_WEIGHT_MAX,\n",
    "    koopman_start_epoch=KOOPMAN_START_EPOCH,\n",
    "    total_epochs=NUM_EPOCHS,\n",
    "    schedule_type='linear',\n",
    "    enable_koopman_updates=True,\n",
    "    fallback_threshold=FALLBACK_THRESHOLD,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Koopman start epoch: {KOOPMAN_START_EPOCH}\")\n",
    "print(f\"  Koopman weight max: {KOOPMAN_WEIGHT_MAX}\")\n",
    "print(f\"  Fallback threshold: {FALLBACK_THRESHOLD}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\nOptimizations:\")\n",
    "print(f\"  ✓ Warning frequency control (1 per epoch max)\")\n",
    "print(f\"  ✓ Automatic weight decay for high Koopman loss\")\n",
    "print(f\"  ✓ Computation skipping when weight is negligible\")\n",
    "print(f\"  ✓ Extended warmup for stable LM convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_loss_lm': [],\n",
    "    'train_loss_koopman': [],\n",
    "    'koopman_weight': [],\n",
    "    'val_loss': [],\n",
    "    'val_perplexity': [],\n",
    "    'epoch_time': [],\n",
    "}\n",
    "\n",
    "# Store initial Koopman operator for comparison\n",
    "initial_K = {}\n",
    "for i, block in enumerate(model.blocks):\n",
    "    initial_K[i] = block.bk_layer.K.data.clone()\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train for one epoch\n",
    "    epoch_metrics = trainer.train_epoch(train_loader, epoch=epoch)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_ppl = trainer.evaluate(val_loader, use_koopman=False)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Store metrics\n",
    "    history['train_loss'].append(epoch_metrics['total_loss'])\n",
    "    history['train_loss_lm'].append(epoch_metrics['loss_lm'])\n",
    "    history['train_loss_koopman'].append(epoch_metrics['loss_koopman'])\n",
    "    history['koopman_weight'].append(epoch_metrics['koopman_weight'])\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_perplexity'].append(val_ppl)\n",
    "    history['epoch_time'].append(epoch_time)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "    print(f\"  Train Loss: {epoch_metrics['total_loss']:.4f} \"\n",
    "          f\"(LM: {epoch_metrics['loss_lm']:.4f}, \"\n",
    "          f\"Koopman: {epoch_metrics['loss_koopman']:.4f})\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val PPL: {val_ppl:.2f}\")\n",
    "    print(f\"  Koopman Weight: {epoch_metrics['koopman_weight']:.4f}\")\n",
    "    print(f\"  Koopman Enabled: {epoch_metrics['koopman_enabled']}\")\n",
    "    print(f\"  Time: {epoch_time:.2f}s\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Koopman Operator Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute change in Koopman operators\n",
    "print(\"\\nKoopman Operator Changes:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, block in enumerate(model.blocks):\n",
    "    final_K = block.bk_layer.K.data\n",
    "    K_diff = (final_K - initial_K[i]).abs().mean().item()\n",
    "    K_norm = final_K.norm().item()\n",
    "    \n",
    "    print(f\"Layer {i}:\")\n",
    "    print(f\"  Mean absolute change: {K_diff:.6f}\")\n",
    "    print(f\"  Final operator norm: {K_norm:.4f}\")\n",
    "    print(f\"  Relative change: {K_diff / K_norm * 100:.2f}%\")\n",
    "\n",
    "# Visualize Koopman operator for first layer\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Initial K\n",
    "im0 = axes[0].imshow(initial_K[0].cpu().numpy(), cmap='RdBu', vmin=-0.1, vmax=0.1)\n",
    "axes[0].set_title('Initial Koopman Operator K (Layer 0)')\n",
    "axes[0].set_xlabel('Dimension')\n",
    "axes[0].set_ylabel('Dimension')\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# Final K\n",
    "final_K_0 = model.blocks[0].bk_layer.K.data.cpu().numpy()\n",
    "im1 = axes[1].imshow(final_K_0, cmap='RdBu', vmin=-0.1, vmax=0.1)\n",
    "axes[1].set_title('Final Koopman Operator K (Layer 0)')\n",
    "axes[1].set_xlabel('Dimension')\n",
    "axes[1].set_ylabel('Dimension')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# Difference\n",
    "K_diff_0 = final_K_0 - initial_K[0].cpu().numpy()\n",
    "im2 = axes[2].imshow(K_diff_0, cmap='RdBu', vmin=-0.05, vmax=0.05)\n",
    "axes[2].set_title('Change in K (Final - Initial)')\n",
    "axes[2].set_xlabel('Dimension')\n",
    "axes[2].set_ylabel('Dimension')\n",
    "plt.colorbar(im2, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('koopman_operator_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Koopman operators have been updated during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs = np.arange(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(epochs, history['train_loss_lm'], 'b-', label='LM Loss', linewidth=2)\n",
    "axes[0, 0].plot(epochs, history['train_loss_koopman'], 'r--', label='Koopman Loss', linewidth=2)\n",
    "axes[0, 0].axvline(x=KOOPMAN_START_EPOCH, color='gray', linestyle=':', label='Koopman Start')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training Loss Components')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Koopman weight schedule\n",
    "axes[0, 1].plot(epochs, history['koopman_weight'], 'g-', linewidth=2)\n",
    "axes[0, 1].axvline(x=KOOPMAN_START_EPOCH, color='gray', linestyle=':', label='Koopman Start')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Weight')\n",
    "axes[0, 1].set_title('Koopman Loss Weight Schedule')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation perplexity\n",
    "axes[1, 0].plot(epochs, history['val_perplexity'], 'purple', linewidth=2, marker='o')\n",
    "axes[1, 0].axvline(x=KOOPMAN_START_EPOCH, color='gray', linestyle=':', label='Koopman Start')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Perplexity')\n",
    "axes[1, 0].set_title('Validation Perplexity')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Training time per epoch\n",
    "axes[1, 1].bar(epochs, history['epoch_time'], color='orange', alpha=0.7)\n",
    "axes[1, 1].axvline(x=KOOPMAN_START_EPOCH, color='gray', linestyle=':', label='Koopman Start')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Time (seconds)')\n",
    "axes[1, 1].set_title('Training Time per Epoch')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('koopman_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results\n",
    "final_val_ppl = history['val_perplexity'][-1]\n",
    "baseline_ppl = 477  # From Step 2 Phase 1 results (corrected)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Final Validation Perplexity: {final_val_ppl:.2f}\")\n",
    "print(f\"Baseline Perplexity (Phase 1): {baseline_ppl:.2f}\")\n",
    "print(f\"Relative Difference: {(final_val_ppl - baseline_ppl) / baseline_ppl * 100:+.1f}%\")\n",
    "\n",
    "# Check if within 30% threshold\n",
    "threshold = 0.30\n",
    "within_threshold = abs(final_val_ppl - baseline_ppl) / baseline_ppl <= threshold\n",
    "\n",
    "if within_threshold:\n",
    "    print(f\"\\n✓ SUCCESS: Perplexity within {threshold*100:.0f}% of baseline\")\n",
    "else:\n",
    "    print(f\"\\n✗ WARNING: Perplexity exceeds {threshold*100:.0f}% threshold\")\n",
    "\n",
    "# Koopman loss convergence\n",
    "# Check from first Koopman-enabled epoch\n",
    "koopman_start_idx = KOOPMAN_START_EPOCH\n",
    "if koopman_start_idx < len(history['train_loss_koopman']) and history['train_loss_koopman'][-1] > 0:\n",
    "    if history['train_loss_koopman'][-1] < history['train_loss_koopman'][koopman_start_idx]:\n",
    "        print(\"✓ Koopman loss decreased during training\")\n",
    "    else:\n",
    "        print(\"✗ Koopman loss did not decrease\")\n",
    "else:\n",
    "    print(\"⚠ Koopman loss not yet active or insufficient data\")\n",
    "# Operator updates\n",
    "K_changed = any(\n",
    "    (model.blocks[i].bk_layer.K.data - initial_K[i]).abs().mean().item() > 1e-6\n",
    "    for i in range(len(model.blocks))\n",
    ")\n",
    "if K_changed:\n",
    "    print(\"✓ Koopman operators updated during training\")\n",
    "else:\n",
    "    print(\"✗ Koopman operators did not change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Koopman Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Koopman prediction\n",
    "print(\"\\nTesting Koopman Prediction Mode:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "val_loss_standard, val_ppl_standard = trainer.evaluate(val_loader, use_koopman=False)\n",
    "val_loss_koopman, val_ppl_koopman = trainer.evaluate(val_loader, use_koopman=True)\n",
    "\n",
    "print(f\"Standard Forward:\")\n",
    "print(f\"  Loss: {val_loss_standard:.4f}\")\n",
    "print(f\"  Perplexity: {val_ppl_standard:.2f}\")\n",
    "print(f\"\\nKoopman Forward:\")\n",
    "print(f\"  Loss: {val_loss_koopman:.4f}\")\n",
    "print(f\"  Perplexity: {val_ppl_koopman:.2f}\")\n",
    "print(f\"\\nDifference: {val_ppl_koopman - val_ppl_standard:+.2f} \"\n",
    "      f\"({(val_ppl_koopman - val_ppl_standard) / val_ppl_standard * 100:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2 PHASE 2: KOOPMAN OPERATOR LEARNING - SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✓ Training completed: {NUM_EPOCHS} epochs\")\n",
    "print(f\"✓ Koopman learning started at epoch {KOOPMAN_START_EPOCH + 1}\")\n",
    "print(f\"✓ Final validation perplexity: {final_val_ppl:.2f}\")\n",
    "print(f\"✓ Koopman operators updated successfully\")\n",
    "print(f\"✓ Koopman loss converged\")\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  Parameters: {total_params:,}\")\n",
    "print(f\"  Koopman dimension: {KOOPMAN_DIM}\")\n",
    "print(f\"  Layers: {N_LAYERS}\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining Strategy:\")\n",
    "print(f\"  Warmup epochs: {KOOPMAN_START_EPOCH} (LM stabilization)\")\n",
    "print(f\"  Hybrid epochs: {NUM_EPOCHS - KOOPMAN_START_EPOCH} (LM + Koopman)\")\n",
    "print(f\"  Max Koopman weight: {KOOPMAN_WEIGHT_MAX} (conservative)\")\n",
    "print(f\"  Fallback threshold: {FALLBACK_THRESHOLD} (automatic decay)\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  - Benchmark backward pass cost reduction\")\n",
    "print(f\"  - Analyze Koopman eigenvalues and eigenfunctions\")\n",
    "print(f\"  - Proceed to Step 2 Phase 3: Physics-Informed Learning\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}