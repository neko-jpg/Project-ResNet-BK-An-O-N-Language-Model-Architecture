{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-BK Interpretability\n",
    "\n",
    "Visualize and understand ResNet-BK internals.\n",
    "\n",
    "This notebook visualizes:\n",
    "- G_ii diagonal elements (real and imaginary)\n",
    "- Learned potential v_i\n",
    "- Expert routing patterns\n",
    "- Attention-like patterns from BK-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets torch matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repo setup (clone if needed, add to sys.path)\n",
    "import os, sys, subprocess, pathlib\n",
    "REPO_URL = 'https://github.com/neko-jpg/Project-ResNet-BK-An-O-N-Language-Model-Architecture.git'\n",
    "REPO_DIR = 'Project-ResNet-BK-An-O-N-Language-Model-Architecture'\n",
    "cwd = pathlib.Path.cwd()\n",
    "candidates = [cwd, cwd.parent, cwd / REPO_DIR, cwd.parent / REPO_DIR]\n",
    "root = next((p for p in candidates if (p / 'src').exists()), None)\n",
    "if root is None:\n    root = cwd / REPO_DIR\n    if not root.exists():\n        subprocess.run(['git', 'clone', REPO_URL, str(root)], check=True)\n",
    "if root != pathlib.Path.cwd():\n    os.chdir(root)\n",
    "root_str = str(pathlib.Path.cwd())\n",
    "if root_str not in sys.path:\n    sys.path.insert(0, root_str)\n",
    "print('PWD:', root_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from src.models import LanguageModel\n",
    "from src.utils import get_data_loader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoints/resnet_bk_final.pt', map_location=device)\n",
    "config = checkpoint['config']\n",
    "\n",
    "model = LanguageModel(**config).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize G_ii Diagonal Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample input\n",
    "train_data, vocab, get_batch = get_data_loader(20, 128)\n",
    "x_batch, _ = get_batch(train_data, 0)\n",
    "x_batch = x_batch.t().contiguous().to(device)\n",
    "\n",
    "# Forward pass and extract G_ii\n",
    "with torch.no_grad():\n",
    "    # Hook to capture BK-Core output\n",
    "    G_ii_features = []\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        G_ii_features.append(output.cpu())\n",
    "    \n",
    "    hook = model.blocks[0].bk_layer.output_proj.register_forward_hook(hook_fn)\n",
    "    _ = model(x_batch)\n",
    "    hook.remove()\n",
    "\n",
    "# Visualize first sample\n",
    "features = G_ii_features[0][0].numpy()  # (N, 2)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(features[:, 0], label='Real(G_ii)')\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.set_title('Real Part of G_ii')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(features[:, 1], label='Imag(G_ii)', color='orange')\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.set_title('Imaginary Part of G_ii')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Potential v_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract potential values\n",
    "with torch.no_grad():\n",
    "    v_values = []\n",
    "    \n",
    "    def hook_v(module, input, output):\n",
    "        v_values.append(output.cpu())\n",
    "    \n",
    "    hook = model.blocks[0].bk_layer.v_proj.register_forward_hook(hook_v)\n",
    "    _ = model(x_batch)\n",
    "    hook.remove()\n",
    "\n",
    "v = v_values[0][0].squeeze().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(v)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Potential v_i')\n",
    "plt.title('Learned Potential Across Sequence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Potential statistics:\")\n",
    "print(f\"  Mean: {v.mean():.4f}\")\n",
    "print(f\"  Std: {v.std():.4f}\")\n",
    "print(f\"  Min: {v.min():.4f}\")\n",
    "print(f\"  Max: {v.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Extract and visualize BK-Core features\n",
    "- Analyze learned potential patterns\n",
    "- Understand model internals\n",
    "\n",
    "**Next steps:**\n",
    "- Analyze expert routing patterns\n",
    "- Compare patterns across different layers\n",
    "- Correlate patterns with linguistic structure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}