#!/usr/bin/env python3
"""
MUSE Concierge - Training Wizard
Auto-configures training parameters based on hardware calibration and user goals.
"""
import os
import sys
import yaml
import time
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, IntPrompt, Confirm
from rich.table import Table
from rich.layout import Layout
from rich.live import Live

# Add root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from scripts.calibration import MuseCalibrator
except ImportError:
    MuseCalibrator = None

# Language
LANG = "1"
if os.path.exists(".muse_config"):
    with open(".muse_config") as f:
        for line in f:
            if "MUSE_LANG" in line:
                LANG = line.strip().split("=")[1].strip("'\"")
IS_JP = (LANG == "2")

def t(en, jp): return jp if IS_JP else en

console = Console()

def main():
    console.print(Panel.fit(
        t("MUSE Concierge - Training Wizard", "MUSE ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ - å­¦ç¿’è¨­å®šã‚¦ã‚£ã‚¶ãƒ¼ãƒ‰"),
        subtitle="Auto-tuning for O(N) Architecture",
        style="bold blue"
    ))

    # 1. Goal Selection
    console.print(t("\nWhat is your goal today?", "\nä»Šæ—¥ã®å­¦ç¿’ã®ç›®çš„ã¯ä½•ã§ã™ã‹ï¼Ÿ"))
    console.print(t("1. Debug (Quick check)", "1. ãƒ‡ãƒãƒƒã‚° (ã¨ã‚Šã‚ãˆãšå‹•ã‹ã™)"))
    console.print(t("2. Benchmark (Push limits)", "2. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ (æ€§èƒ½ã®é™ç•Œã«æŒ‘æˆ¦)"))
    console.print(t("3. Production (Train a good model)", "3. æœ¬ç•ªå­¦ç¿’ (è‰¯ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹)"))

    goal = IntPrompt.ask("Choice", choices=["1", "2", "3"], default="1")

    # 2. Calibration
    cal = MuseCalibrator()
    if cal and cal.device.type == 'cuda':
        if Confirm.ask(t("Run hardware calibration?", "ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¨ºæ–­ï¼ˆã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ"), default=True):
            cal.calibrate()
    else:
        console.print(t("[yellow]Skipping calibration (CPU or module missing).[/yellow]", "[yellow]ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚[/yellow]"))

    # 3. Dataset Recipe
    data_dir = Path("data")
    available_datasets = []
    if data_dir.exists():
        for d in data_dir.iterdir():
            if d.is_dir() and d.name != 'import' and (d / "metadata.json").exists():
                available_datasets.append(d.name)

    ratios = {}
    if available_datasets:
        console.print(t("\n[Dataset Recipe]", "\n[ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé…åˆ]"))
        remaining = 100
        for i, ds in enumerate(available_datasets):
            if i == len(available_datasets) - 1:
                val = remaining
                console.print(f"- {ds}: [bold]{val}%[/bold] (Auto-filled)")
            else:
                val = IntPrompt.ask(f"- {ds} (Remaining: {remaining}%)", default=0)
                val = min(val, remaining)
            ratios[ds] = val / 100.0
            remaining -= val
    else:
        console.print(t("[yellow]No datasets found. Using default logic.[/yellow]", "[yellow]ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚[/yellow]"))

    # 4. Parameter Proposal
    # Default params
    d_model = 512
    n_layers = 6
    batch_size = 4
    seq_len = 1024
    epochs = 1

    # Logic based on goal & calibration
    if goal == "1": # Debug
        d_model, n_layers = 256, 4
        batch_size, seq_len = 2, 512
        epochs = 1
    elif goal == "2": # Benchmark
        d_model, n_layers = 1024, 12
        batch_size, seq_len = 1, 8192 # Push seq len
        epochs = 1
    elif goal == "3": # Production
        d_model, n_layers = 768, 12
        batch_size, seq_len = 8, 2048
        epochs = 3

    # Apply calibration limits if available
    if cal and cal.memory_coeffs['base'] > 0:
        mem, _ = cal.predict(batch_size, seq_len, d_model, n_layers)
        limit = cal.vram_total * 0.9

        if mem > limit:
            console.print(t(f"[red]Proposal {mem:.0f}MB exceeds VRAM {limit:.0f}MB. Downgrading...[/red]", f"[red]ææ¡ˆè¨­å®š ({mem:.0f}MB) ãŒVRAM ({limit:.0f}MB) ã‚’è¶…ãˆã¾ã™ã€‚è¨­å®šã‚’ä¸‹ã’ã¾ã™...[/red]"))
            while mem > limit and batch_size > 1:
                batch_size = max(1, batch_size // 2)
                mem, _ = cal.predict(batch_size, seq_len, d_model, n_layers)

            while mem > limit and seq_len > 512:
                seq_len = seq_len // 2
                mem, _ = cal.predict(batch_size, seq_len, d_model, n_layers)

    # Show Proposal
    table = Table(title=t("Recommended Configuration", "æ¨å¥¨è¨­å®š"))
    table.add_column("Parameter", style="cyan")
    table.add_column("Value", style="magenta")

    table.add_row("d_model", str(d_model))
    table.add_row("n_layers", str(n_layers))
    table.add_row("Batch Size", str(batch_size))
    table.add_row("Sequence Length", str(seq_len))
    table.add_row("Epochs", str(epochs))

    if cal and cal.memory_coeffs['base'] > 0:
        pred_mem, pred_time = cal.predict(batch_size, seq_len, d_model, n_layers)
        table.add_row("Est. VRAM", f"{pred_mem:.0f} MB / {cal.vram_total:.0f} MB")

    console.print(table)

    if not Confirm.ask(t("Accept this configuration?", "ã“ã®è¨­å®šã§æ±ºå®šã—ã¾ã™ã‹ï¼Ÿ"), default=True):
        console.print(t("Manual tuning not yet implemented. Using proposed config.", "æ‰‹å‹•èª¿æ•´ã¯æœªå®Ÿè£…ã§ã™ã€‚ææ¡ˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"))

    # 5. Save
    config_dir = Path("configs")
    config_dir.mkdir(exist_ok=True)

    # Save Recipe
    with open(config_dir / "dataset_mixing.yaml", 'w') as f:
        yaml.dump({'mixing_ratios': ratios}, f)

    # Save Train Config
    train_config = {
        'd_model': d_model,
        'n_layers': n_layers,
        'batch_size': batch_size,
        'n_seq': seq_len,
        'epochs': epochs,
        'learning_rate': 1e-4 if goal == "3" else 1e-3
    }
    with open(config_dir / "user_train_config.yaml", 'w') as f:
        yaml.dump(train_config, f)

    console.print(t("\n[bold green]Ready to fly! ğŸš€[/bold green]", "\n[bold green]æº–å‚™å®Œäº†ï¼ ğŸš€[/bold green]"))
    console.print(t("Run 'make train-user' to start.", "'make train-user' ã§ç™ºé€²ã—ã¦ãã ã•ã„ã€‚"))

if __name__ == "__main__":
    main()
