#!/usr/bin/env python3
"""
è¨“ç·´å‰åŒ…æ‹¬çš„æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»¥ä¸‹ã‚’æ¤œè¨¼:
1. å› æœãƒã‚¹ã‚¯ï¼ˆã‚«ãƒ³ãƒ‹ãƒ³ã‚°é˜²æ­¢ï¼‰
2. ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
3. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
4. åˆæœŸåŒ–ãƒ»å‹¾é…
5. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import os
os.environ["CUDA_VISIBLE_DEVICES"] = ""  # CPU only for quick testing

import random
import numpy as np
import yaml

print("=" * 70)
print("è¨“ç·´å‰åŒ…æ‹¬çš„æ¤œè¨¼")
print("=" * 70)

results = {"passed": 0, "failed": 0, "warnings": 0}

def check(name, condition, critical=True):
    """Check a condition and report result."""
    if condition:
        print(f"âœ… {name}")
        results["passed"] += 1
        return True
    elif critical:
        print(f"âŒ {name}")
        results["failed"] += 1
        return False
    else:
        print(f"âš ï¸  {name}")
        results["warnings"] += 1
        return False

# =============================================================================
# 1. å› æœãƒã‚¹ã‚¯æ¤œè¨¼
# =============================================================================
print("\n--- 1. å› æœãƒã‚¹ã‚¯ï¼ˆã‚«ãƒ³ãƒ‹ãƒ³ã‚°é˜²æ­¢ï¼‰æ¤œè¨¼ ---")

# Check hybrid_attention.py for torch.tril
hybrid_attention_path = Path("src/models/phase7/hybrid_attention.py")
if hybrid_attention_path.exists():
    content = hybrid_attention_path.read_text()
    check("HybridHyperbolicAttention: torch.trilãŒå­˜åœ¨", "torch.tril" in content)
    check("HybridHyperbolicAttention: causalãƒã‚¹ã‚¯é–¢é€£ã‚³ãƒ¡ãƒ³ãƒˆãŒå­˜åœ¨", "causal" in content.lower())
else:
    check("hybrid_attention.pyãŒå­˜åœ¨", False)

# Check hyperbolic_attention.py for mask application
hyperbolic_attention_path = Path("src/models/phase7/hyperbolic_attention.py")
if hyperbolic_attention_path.exists():
    content = hyperbolic_attention_path.read_text()
    check("HyperbolicAttention: masked_fillãŒå­˜åœ¨", "masked_fill" in content)
    check("HyperbolicAttention: maskå¼•æ•°ãŒå­˜åœ¨", "mask=" in content or "mask:" in content)
else:
    check("hyperbolic_attention.pyãŒå­˜åœ¨", False)

# =============================================================================
# 2. ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼
# =============================================================================
print("\n--- 2. ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼ ---")

from src.utils.data_utils import BinaryIndexedDataset

# Test short document concatenation logic
try:
    ds = BinaryIndexedDataset("data/japanese_instruct", split="train")
    rng = random.Random(42)
    
    # Test sampling with seq_len larger than some documents
    result = ds.sample_sequence(512, rng)
    check("sample_sequence: 512ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒæˆåŠŸ", result is not None)
    
    if result:
        x, y = result
        check("sample_sequence: x.shape == (512,)", len(x) == 512)
        check("sample_sequence: y.shape == (512,)", len(y) == 512)
        check("sample_sequence: ãƒˆãƒ¼ã‚¯ãƒ³å€¤ãŒæ­£ã®æ•´æ•°", x.min() >= 0 and y.min() >= 0)
except Exception as e:
    check(f"sample_sequenceãƒ†ã‚¹ãƒˆ: ã‚¨ãƒ©ãƒ¼ - {e}", False)

# Check all 4 datasets
datasets = ["japanese_instruct", "dolly_ja", "wiki_ja", "mc4_ja"]
for ds_name in datasets:
    ds_path = Path(f"data/{ds_name}/train.idx")
    if ds_path.exists():
        try:
            ds = BinaryIndexedDataset(f"data/{ds_name}", split="train")
            check(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ {ds_name}: ãƒ­ãƒ¼ãƒ‰æˆåŠŸ ({ds.num_docs} docs)", ds.num_docs > 0)
        except Exception as e:
            check(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ {ds_name}: ã‚¨ãƒ©ãƒ¼ - {e}", False)
    else:
        check(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ {ds_name}: train.idxãŒå­˜åœ¨", False, critical=False)

# =============================================================================
# 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
# =============================================================================
print("\n--- 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ ---")

# Check dataset config
dataset_config_path = Path("configs/dataset_japanese_chat_optimized.yaml")
if dataset_config_path.exists():
    with open(dataset_config_path) as f:
        ds_config = yaml.safe_load(f)
    
    datasets_in_config = ds_config.get("datasets", {})
    total_weight = sum(d.get("weight", 0) for d in datasets_in_config.values())
    check(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé‡ã¿åˆè¨ˆ: {total_weight:.2f} (æœŸå¾…å€¤: 1.0)", abs(total_weight - 1.0) < 0.01)
    
    for name, cfg in datasets_in_config.items():
        path = Path(cfg.get("path", ""))
        check(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ {name}: ãƒ‘ã‚¹ãŒå­˜åœ¨", (path / "train.bin").exists() or (Path("data") / name / "train.bin").exists(), critical=False)
else:
    check("dataset_japanese_chat_optimized.yamlãŒå­˜åœ¨", False)

# Check model config
model_config_path = Path("configs/phase8_300m_japanese_chat.yaml")
if model_config_path.exists():
    with open(model_config_path) as f:
        model_config = yaml.safe_load(f)
    
    n_seq = model_config.get("n_seq", 0)
    check(f"n_seq: {n_seq} (æœŸå¾…å€¤: 256-2048)", 256 <= n_seq <= 2048)
    
    lr = model_config.get("learning_rate", model_config.get("lr", 0))
    check(f"å­¦ç¿’ç‡: {lr} (æœŸå¾…å€¤: 1e-5 ~ 1e-3)", 1e-6 <= lr <= 1e-2)
    
    batch_size = model_config.get("batch_size", 0)
    check(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size} (æœŸå¾…å€¤: 1-64)", 1 <= batch_size <= 64)
else:
    check("phase8_300m_japanese_chat.yamlãŒå­˜åœ¨", False)

# =============================================================================
# 4. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¤œè¨¼
# =============================================================================
print("\n--- 4. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¤œè¨¼ ---")

try:
    import torch
    from src.models.configurable_resnet_bk import ResNetBKConfig, ConfigurableResNetBK
    
    # Create small test model
    test_config = ResNetBKConfig(
        d_model=64,
        n_layers=2,
        n_seq=32,
        num_heads=4,
        vocab_size=1000,
        model_type="resnet_bk",
    )
    
    model = ConfigurableResNetBK(test_config)
    check("ãƒ¢ãƒ‡ãƒ«: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–æˆåŠŸ", model is not None)
    
    # Test forward pass
    x = torch.randint(0, 1000, (2, 32))  # batch=2, seq=32
    
    with torch.no_grad():
        output = model(x)
    
    if isinstance(output, tuple):
        logits = output[0]
    else:
        logits = output
    
    check("ãƒ¢ãƒ‡ãƒ«: forwardæˆåŠŸ", logits is not None)
    check(f"ãƒ¢ãƒ‡ãƒ«: å‡ºåŠ›å½¢çŠ¶ {logits.shape} (æœŸå¾…: [2, 32, 1000])", logits.shape == (2, 32, 1000))
    check("ãƒ¢ãƒ‡ãƒ«: NaNãªã—", not torch.isnan(logits).any().item())
    check("ãƒ¢ãƒ‡ãƒ«: Infãªã—", not torch.isinf(logits).any().item())
    
    # Test gradient flow
    model.train()
    x = torch.randint(0, 1000, (2, 32))
    y = torch.randint(0, 1000, (2, 32))
    
    output = model(x)
    if isinstance(output, tuple):
        logits = output[0]
    else:
        logits = output
    
    loss = torch.nn.functional.cross_entropy(logits.view(-1, 1000), y.view(-1))
    loss.backward()
    
    # Check gradient norms
    total_grad_norm = 0.0
    param_count = 0
    for p in model.parameters():
        if p.grad is not None:
            total_grad_norm += p.grad.norm().item() ** 2
            param_count += 1
    total_grad_norm = total_grad_norm ** 0.5
    
    check(f"å‹¾é…: ãƒãƒ«ãƒ ={total_grad_norm:.4f} (æœŸå¾…: > 0)", total_grad_norm > 0.001)
    check(f"å‹¾é…: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°={param_count} (æœŸå¾…: > 0)", param_count > 0)
    
    # Check initial loss
    expected_random_loss = np.log(1000)  # ~6.9 for vocab_size=1000
    check(f"åˆæœŸæå¤±: {loss.item():.2f} (ãƒ©ãƒ³ãƒ€ãƒ æœŸå¾…å€¤: ~{expected_random_loss:.1f})", 
          abs(loss.item() - expected_random_loss) < 3.0)
    
except Exception as e:
    import traceback
    print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
    traceback.print_exc()
    results["failed"] += 1

# =============================================================================
# 5. BK-Core/AR-SSMæ¥ç¶šæ¤œè¨¼
# =============================================================================
print("\n--- 5. BK-Core/AR-SSMæ¥ç¶šæ¤œè¨¼ ---")

integrated_model_path = Path("src/models/phase8/integrated_model.py")
if integrated_model_path.exists():
    content = integrated_model_path.read_text()
    check("IntegratedModel: BK-Coreå‚ç…§ãŒå­˜åœ¨", "bk_core" in content.lower() or "bk-core" in content.lower())
    check("IntegratedModel: SSMå‚ç…§ãŒå­˜åœ¨", "ssm" in content.lower())
    check("IntegratedModel: æ®‹å·®æ¥ç¶šãŒå­˜åœ¨", "residual" in content.lower() or "+=" in content or "+ x" in content or "x +" in content)

# =============================================================================
# æœ€çµ‚çµæœ
# =============================================================================
print("\n" + "=" * 70)
print("æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
print("=" * 70)
print(f"âœ… åˆæ ¼: {results['passed']}")
print(f"âŒ å¤±æ•—: {results['failed']}")
print(f"âš ï¸  è­¦å‘Š: {results['warnings']}")

if results["failed"] == 0:
    print("\nğŸ‰ ã™ã¹ã¦ã®æ¤œè¨¼ã«åˆæ ¼ã—ã¾ã—ãŸï¼è¨“ç·´ã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
    sys.exit(0)
else:
    print(f"\nâš ï¸  {results['failed']}ä»¶ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
    sys.exit(1)
