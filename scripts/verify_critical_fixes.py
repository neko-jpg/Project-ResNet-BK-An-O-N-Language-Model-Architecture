#!/usr/bin/env python3
"""
Phase 1 Critical Fixes Verification Script

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€AGENTS.mdã§æŒ‡å®šã•ã‚ŒãŸğŸš¨æœ€å„ªå…ˆä¿®æ­£é …ç›®ãŒ
æ­£ã—ãå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    python scripts/verify_critical_fixes.py

Author: Project MUSE Team
Date: 2025-11-19
"""

import sys
import os
import torch
import warnings

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# è‰²ä»˜ãå‡ºåŠ›ç”¨
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    END = '\033[0m'
    BOLD = '\033[1m'

def print_header(text):
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'='*80}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.BLUE}{text:^80}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.BLUE}{'='*80}{Colors.END}\n")

def print_success(text):
    try:
        print(f"{Colors.GREEN}âœ“ {text}{Colors.END}")
    except UnicodeEncodeError:
        print(f"{Colors.GREEN}[OK] {text}{Colors.END}")

def print_error(text):
    try:
        print(f"{Colors.RED}âœ— {text}{Colors.END}")
    except UnicodeEncodeError:
        print(f"{Colors.RED}[ERROR] {text}{Colors.END}")

def print_warning(text):
    try:
        print(f"{Colors.YELLOW}âš  {text}{Colors.END}")
    except UnicodeEncodeError:
        print(f"{Colors.YELLOW}[WARNING] {text}{Colors.END}")

def print_info(text):
    try:
        print(f"{Colors.BLUE}â„¹ {text}{Colors.END}")
    except UnicodeEncodeError:
        print(f"{Colors.BLUE}[INFO] {text}{Colors.END}")


def verify_tt_contraction():
    """HTTå±•é–‹ãªã—æ¼”ç®—ã®æ¤œè¨¼"""
    print_header("1. HTT (Tensor Train) å±•é–‹ãªã—æ¼”ç®—ã®æ¤œè¨¼")
    
    try:
        # tt_contractionã‚«ãƒ¼ãƒãƒ«ã®å­˜åœ¨ç¢ºèª
        from src.kernels.tt_contraction import (
            tt_contraction_memory_efficient,
            TRITON_AVAILABLE
        )
        print_success("tt_contraction_memory_efficient ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
        B, L = 2, 10
        v1, v2 = 100, 100
        rank, d1, d2 = 8, 32, 32
        d_model = 1024
        
        idx1 = torch.randint(0, v1, (B, L))
        idx2 = torch.randint(0, v2, (B, L))
        core1 = torch.randn(v1, rank, d1)
        core2 = torch.randn(v2, rank, d2)
        
        # CPUå®Ÿè¡Œ
        output = tt_contraction_memory_efficient(
            idx1, idx2, core1, core2, d_model, use_triton=False
        )
        
        assert output.shape == (B, L, d_model), f"å‡ºåŠ›å½¢çŠ¶ãŒä¸æ­£: {output.shape}"
        print_success(f"CPUå®Ÿè¡ŒæˆåŠŸ: å‡ºåŠ›å½¢çŠ¶ {output.shape}")
        
        # CUDAå®Ÿè¡Œï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if torch.cuda.is_available() and TRITON_AVAILABLE:
            try:
                idx1_cuda = idx1.cuda()
                idx2_cuda = idx2.cuda()
                core1_cuda = core1.cuda()
                core2_cuda = core2.cuda()
                
                output_cuda = tt_contraction_memory_efficient(
                    idx1_cuda, idx2_cuda, core1_cuda, core2_cuda, d_model, use_triton=True
                )
                
                assert output_cuda.shape == (B, L, d_model), f"CUDAå‡ºåŠ›å½¢çŠ¶ãŒä¸æ­£: {output_cuda.shape}"
                print_success(f"CUDAå®Ÿè¡ŒæˆåŠŸ: å‡ºåŠ›å½¢çŠ¶ {output_cuda.shape}")
            except Exception as e:
                print_warning(f"CUDAå®Ÿè¡Œã‚¹ã‚­ãƒƒãƒ—: {e}")
        else:
            print_warning("CUDA/Tritonåˆ©ç”¨ä¸å¯ã€CPUå®Ÿè¡Œã®ã¿")
        
        # HTT Embeddingã§ã®çµ±åˆç¢ºèª
        from src.models.phase1.htt_embedding import HolographicTTEmbedding
        
        embedding = HolographicTTEmbedding(vocab_size=1000, d_model=128, rank=8)
        input_ids = torch.randint(0, 1000, (2, 10))
        output = embedding(input_ids)
        
        assert output.shape == (2, 10, 128), f"Embeddingå‡ºåŠ›å½¢çŠ¶ãŒä¸æ­£: {output.shape}"
        print_success("HTT Embeddingã§ã®çµ±åˆç¢ºèªæˆåŠŸ")
        
        # åœ§ç¸®ç‡ã®ç¢ºèª
        compression_ratio = embedding.get_compression_ratio()
        print_info(f"åœ§ç¸®ç‡: {compression_ratio:.4f} ({(1-compression_ratio)*100:.1f}%å‰Šæ¸›)")
        
        return True
        
    except Exception as e:
        print_error(f"HTTæ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_lns_precision():
    """LNSåŠ ç®—ç²¾åº¦ã®æ¤œè¨¼"""
    print_header("2. LNS (å¯¾æ•°æ•°ç³») åŠ ç®—ç²¾åº¦ã®æ¤œè¨¼")
    
    try:
        from src.kernels.lns_kernel import lns_matmul, TRITON_AVAILABLE
        
        print_success("lns_matmul ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # log1pãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼ˆã‚³ãƒ¼ãƒ‰æ¤œæŸ»ï¼‰
        import inspect
        source = inspect.getsource(lns_matmul)
        
        if 'log1p' in source or 'correction' in source:
            print_success("LNSã‚«ãƒ¼ãƒãƒ«ã«log1p/è£œæ­£é …ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª")
        else:
            print_warning("LNSã‚«ãƒ¼ãƒãƒ«ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã§log1p/è£œæ­£é …ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # æ•°å€¤ç²¾åº¦ãƒ†ã‚¹ãƒˆï¼ˆCUDAåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if torch.cuda.is_available() and TRITON_AVAILABLE:
            M, N, K = 64, 64, 64
            
            # ãƒ­ã‚°é ˜åŸŸã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            log_a = torch.randn(M, K, device='cuda')
            log_b = torch.randn(K, N, device='cuda')
            
            # LNS matmulå®Ÿè¡Œ
            log_c = lns_matmul(log_a, log_b)
            
            assert log_c.shape == (M, N), f"LNSå‡ºåŠ›å½¢çŠ¶ãŒä¸æ­£: {log_c.shape}"
            assert torch.isfinite(log_c).all(), "LNSå‡ºåŠ›ã«NaN/InfãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
            
            print_success(f"LNS matmulå®Ÿè¡ŒæˆåŠŸ: å‡ºåŠ›å½¢çŠ¶ {log_c.shape}")
            print_info(f"å‡ºåŠ›ç¯„å›²: [{log_c.min():.2f}, {log_c.max():.2f}]")
        else:
            print_warning("CUDA/Tritonåˆ©ç”¨ä¸å¯ã€æ•°å€¤ç²¾åº¦ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
        
        return True
        
    except Exception as e:
        print_error(f"LNSæ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_ar_ssm_gates():
    """AR-SSMã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã®æ¤œè¨¼"""
    print_header("3. AR-SSM ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ (STE/Gumbel-Softmax) ã®æ¤œè¨¼")
    
    try:
        from src.models.phase1.ar_ssm_layer import AdaptiveRankSemiseparableLayer
        
        print_success("AdaptiveRankSemiseparableLayer ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½œæˆ
        layer = AdaptiveRankSemiseparableLayer(d_model=128, max_rank=16)
        
        # set_gate_modeãƒ¡ã‚½ãƒƒãƒ‰ã®å­˜åœ¨ç¢ºèª
        assert hasattr(layer, 'set_gate_mode'), "set_gate_modeãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        print_success("set_gate_modeãƒ¡ã‚½ãƒƒãƒ‰ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
        
        # å„ã‚²ãƒ¼ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
        x = torch.randn(2, 10, 128)
        
        for mode in ['soft', 'ste', 'gumbel']:
            layer.set_gate_mode(mode)
            output, diagnostics = layer(x)
            
            assert output.shape == x.shape, f"{mode}ãƒ¢ãƒ¼ãƒ‰: å‡ºåŠ›å½¢çŠ¶ãŒä¸æ­£"
            assert 'gates' in diagnostics, f"{mode}ãƒ¢ãƒ¼ãƒ‰: diagnosticsã«gatesãŒã‚ã‚Šã¾ã›ã‚“"
            
            # å‹¾é…ãƒ•ãƒ­ãƒ¼ã®ç¢ºèª
            loss = output.sum()
            loss.backward()
            
            # ã‚²ãƒ¼ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å‹¾é…ãŒæµã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            has_grad = any(p.grad is not None for p in layer.complexity_gate.parameters())
            assert has_grad, f"{mode}ãƒ¢ãƒ¼ãƒ‰: ã‚²ãƒ¼ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å‹¾é…ãŒæµã‚Œã¦ã„ã¾ã›ã‚“"
            
            print_success(f"{mode}ãƒ¢ãƒ¼ãƒ‰: å‹•ä½œç¢ºèªæˆåŠŸã€å‹¾é…ãƒ•ãƒ­ãƒ¼æ­£å¸¸")
            
            # å‹¾é…ã‚’ã‚¯ãƒªã‚¢
            layer.zero_grad()
        
        return True
        
    except Exception as e:
        print_error(f"AR-SSMã‚²ãƒ¼ãƒˆæ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_triton_autotune():
    """Tritonè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ¤œè¨¼"""
    print_header("4. Triton ã‚«ãƒ¼ãƒãƒ«è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ¤œè¨¼")
    
    try:
        import inspect
        
        lns_found = False
        scan_found = False
        
        # LNSã‚«ãƒ¼ãƒãƒ«ã®è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç¢ºèª
        try:
            import src.kernels.lns_kernel as lns_module
            source = inspect.getsource(lns_module)
            if '@triton.autotune' in source:
                print_success("LNSã‚«ãƒ¼ãƒãƒ«ã«@triton.autotuneãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                lns_found = True
                
                # è¨­å®šæ•°ã‚’ç¢ºèª
                import re
                configs = re.findall(r'triton\.Config\(', source)
                print_info(f"  LNSè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šæ•°: {len(configs)}")
            else:
                print_warning("LNSã‚«ãƒ¼ãƒãƒ«ã«@triton.autotuneãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            print_warning(f"LNSã‚«ãƒ¼ãƒãƒ«ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ç¢ºèªã«å¤±æ•—: {e}")
        
        # Associative Scanã‚«ãƒ¼ãƒãƒ«ã®è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç¢ºèª
        try:
            import src.kernels.associative_scan as scan_module
            source = inspect.getsource(scan_module)
            if '@triton.autotune' in source:
                print_success("Associative Scanã‚«ãƒ¼ãƒãƒ«ã«@triton.autotuneãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                scan_found = True
                
                # è¨­å®šæ•°ã‚’ç¢ºèª
                import re
                configs = re.findall(r'triton\.Config\(', source)
                print_info(f"  Scanè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šæ•°: {len(configs)}")
            else:
                print_warning("Associative Scanã‚«ãƒ¼ãƒãƒ«ã«@triton.autotuneãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            print_warning(f"Associative Scanã‚«ãƒ¼ãƒãƒ«ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ç¢ºèªã«å¤±æ•—: {e}")
        
        # ä¸¡æ–¹è¦‹ã¤ã‹ã£ãŸå ´åˆã®ã¿æˆåŠŸ
        if lns_found and scan_found:
            print_success("ã™ã¹ã¦ã®ã‚«ãƒ¼ãƒãƒ«ã«è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
            return True
        elif lns_found or scan_found:
            print_warning("ä¸€éƒ¨ã®ã‚«ãƒ¼ãƒãƒ«ã®ã¿è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
            return True  # éƒ¨åˆ†çš„æˆåŠŸã¨ã—ã¦æ‰±ã†
        else:
            print_error("è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
    except Exception as e:
        print_error(f"è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_recovery_logic():
    """å®‰å®šæ€§å›å¾©ãƒ­ã‚¸ãƒƒã‚¯ã®æ¤œè¨¼"""
    print_header("5. å®‰å®šæ€§ç›£è¦–å›å¾©ãƒ­ã‚¸ãƒƒã‚¯ã®æ¤œè¨¼")
    
    try:
        from src.models.phase1.recovery import Phase1ErrorRecovery
        
        print_success("Phase1ErrorRecovery ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # å›å¾©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        recovery = Phase1ErrorRecovery(
            enable_checkpoint_rollback=True,
            checkpoint_save_interval=100,
        )
        
        # æ–°æ©Ÿèƒ½ã®å­˜åœ¨ç¢ºèª
        assert hasattr(recovery, 'save_checkpoint'), "save_checkpointãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        assert hasattr(recovery, 'rollback_to_checkpoint'), "rollback_to_checkpointãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        assert hasattr(recovery, 'reinitialize_layer'), "reinitialize_layerãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
        
        print_success("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
        print_success("å±¤ã®éƒ¨åˆ†çš„å†åˆæœŸåŒ–æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
        
        # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
        import torch.nn as nn
        
        model = nn.Sequential(
            nn.Linear(10, 20),
            nn.ReLU(),
            nn.Linear(20, 10),
        )
        
        optimizer = torch.optim.Adam(model.parameters())
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        recovery.save_checkpoint(model, optimizer, step=100)
        assert recovery.last_stable_checkpoint is not None, "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        print_success("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜æˆåŠŸ")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´
        with torch.no_grad():
            for p in model.parameters():
                p.add_(1.0)
        
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
        success = recovery.rollback_to_checkpoint(model, optimizer)
        assert success, "ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ"
        print_success("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ")
        
        # å±¤ã®å†åˆæœŸåŒ–
        success = recovery.reinitialize_layer(model, '0')  # æœ€åˆã®Linearå±¤
        assert success, "å±¤ã®å†åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"
        print_success("å±¤ã®éƒ¨åˆ†çš„å†åˆæœŸåŒ–æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print_error(f"å›å¾©ãƒ­ã‚¸ãƒƒã‚¯æ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_dependencies():
    """ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¤œè¨¼"""
    print_header("6. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ¤œè¨¼")
    
    try:
        # requirements.txtã®èª­ã¿è¾¼ã¿
        with open('requirements.txt', 'r') as f:
            requirements = f.read()
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šã®ç¢ºèª
        critical_packages = {
            'torch': '2.1.0',
            'triton': '2.1.0',
        }
        
        all_fixed = True
        for package, expected_version in critical_packages.items():
            if f'{package}=={expected_version}' in requirements:
                print_success(f"{package}=={expected_version} ãŒå›ºå®šã•ã‚Œã¦ã„ã¾ã™")
            else:
                print_error(f"{package}ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒ{expected_version}ã«å›ºå®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                all_fixed = False
        
        # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç¢ºèª
        import torch
        print_info(f"ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿torchãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}")
        
        try:
            import triton
            print_info(f"ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿tritonãƒãƒ¼ã‚¸ãƒ§ãƒ³: {triton.__version__}")
        except ImportError:
            print_warning("tritonãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        return all_fixed
        
    except Exception as e:
        print_error(f"ä¾å­˜é–¢ä¿‚æ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_presets():
    """ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®šã®æ¤œè¨¼"""
    print_header("7. ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®šã®æ¤œè¨¼")
    
    try:
        from src.models.phase1.presets import get_preset, list_presets
        
        print_success("ãƒ—ãƒªã‚»ãƒƒãƒˆé–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã®ãƒ†ã‚¹ãƒˆ
        aliases = {
            'speed_oriented': '24gb',
            'memory_oriented': '8gb',
            'balanced': '10gb',
        }
        
        for alias, expected in aliases.items():
            try:
                config = get_preset(alias)
                print_success(f"ã‚¨ã‚¤ãƒªã‚¢ã‚¹ '{alias}' ãŒå‹•ä½œã—ã¾ã™")
            except Exception as e:
                print_error(f"ã‚¨ã‚¤ãƒªã‚¢ã‚¹ '{alias}' ãŒå‹•ä½œã—ã¾ã›ã‚“: {e}")
                return False
        
        # ãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§ã®å–å¾—
        presets = list_presets()
        print_info(f"åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒªã‚»ãƒƒãƒˆæ•°: {len(presets)}")
        
        return True
        
    except Exception as e:
        print_error(f"ãƒ—ãƒªã‚»ãƒƒãƒˆæ¤œè¨¼å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³æ¤œè¨¼é–¢æ•°"""
    print_header("Phase 1 Critical Fixes Verification")
    print_info("AGENTS.mdã§æŒ‡å®šã•ã‚ŒãŸğŸš¨æœ€å„ªå…ˆä¿®æ­£é …ç›®ã®æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™")
    
    results = {}
    
    # å„æ¤œè¨¼ã‚’å®Ÿè¡Œ
    results['HTTå±•é–‹ãªã—æ¼”ç®—'] = verify_tt_contraction()
    results['LNSåŠ ç®—ç²¾åº¦'] = verify_lns_precision()
    results['AR-SSMã‚²ãƒ¼ãƒˆ'] = verify_ar_ssm_gates()
    results['Tritonè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°'] = verify_triton_autotune()
    results['å›å¾©ãƒ­ã‚¸ãƒƒã‚¯'] = verify_recovery_logic()
    results['ä¾å­˜é–¢ä¿‚'] = verify_dependencies()
    results['ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š'] = verify_presets()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print_header("æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
    
    total = len(results)
    passed = sum(results.values())
    failed = total - passed
    
    for name, result in results.items():
        if result:
            print_success(f"{name}: åˆæ ¼")
        else:
            print_error(f"{name}: ä¸åˆæ ¼")
    
    print()
    print(f"{Colors.BOLD}åˆè¨ˆ: {passed}/{total} é …ç›®ãŒåˆæ ¼{Colors.END}")
    
    if failed == 0:
        try:
            print(f"\n{Colors.GREEN}{Colors.BOLD}âœ“ ã™ã¹ã¦ã®æ¤œè¨¼ã«åˆæ ¼ã—ã¾ã—ãŸï¼{Colors.END}")
        except UnicodeEncodeError:
            print(f"\n{Colors.GREEN}{Colors.BOLD}[SUCCESS] ã™ã¹ã¦ã®æ¤œè¨¼ã«åˆæ ¼ã—ã¾ã—ãŸï¼{Colors.END}")
        print(f"{Colors.GREEN}Phase 2ã¸ã®ç§»è¡Œæº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{Colors.END}\n")
        return 0
    else:
        try:
            print(f"\n{Colors.RED}{Colors.BOLD}âœ— {failed}é …ç›®ãŒä¸åˆæ ¼ã§ã™ã€‚{Colors.END}")
        except UnicodeEncodeError:
            print(f"\n{Colors.RED}{Colors.BOLD}[FAILED] {failed}é …ç›®ãŒä¸åˆæ ¼ã§ã™ã€‚{Colors.END}")
        print(f"{Colors.RED}ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚{Colors.END}\n")
        return 1


if __name__ == '__main__':
    sys.exit(main())
